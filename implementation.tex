\section{Implementation}\label{sec:impl}  % [lmr3796] added

\subsection{System Flow}	%%% [DS] added

Figure~\ref{fig:archi-overview} shows our system flow.
1) The client sends a job request to the Dispatcher in the management 
system.
2) According to the pre-defined policy and current worker status, the 
Decision maker generates a resource allocation plan.
The dispatcher responds to the client about which worker and
corresponding job the client should execute next task on.
3) The client transfer the required data to workers.
4) The client sends tells the management system a task is sent
(maintaining remaining tasks of each job is critical to scheduling).
5) After finishing the task, the worker sends ``job done'' signal to the
management system.
6) On receiving the ``job done'' signal,  the management system informs
the corresponding client.
7) The client collects the job results from workers, and
8) send an acknowledgement to workers after the transmission is 
completed.
9) Last, the worker send a ``clear'' signal to management system.

\subsection{RPC Server Component}

% RPC server design
We implemented the components in the {\em management system} and the
{\em worker} as separate RPC (remote procedural call)~\cite{cite:RPC}
servers.
Separate RPC server implementation makes each component {\em pluggable}.
The pluggability gives the system administrator flexibility to choose
the most suitable component implementation to fit different needs.
Moreover, without shutting the whole system down, it is possible to
change system configurations --- or even upgrade the system --- by
substituting target components with feasible ones.
Besides, this design allows us to easily integrate the management system
with other cluster management frameworks like JPPF~\cite{cite:JPPF} or
cloud operating system like Roystonea~\cite{cite:roystonea}.
Roystonea also benefits from the RPC server implementation.

\subsection{Message Service} % [lmr3796] added

Our implementation is a pure client-server model, which means the
management system and workers cannot actively contact the clients.
However, it is essential for workers and the management system to notify
clients to submit tasks or get back execution results as soon as a task
is done.

It is extremely inefficient for both side and server side to keep the
connection between the client and the management system along the
period.
The connection may last over hours if we keep it alive between task
submission to worker and the finish of task execution, depending on how
long a task is required to execute.
Moreover, as the number of long-last connections increases, the
connection number limit from the operating system will become the
bottleneck of the management system.

In order to overcome this, we implemented a underlying message push
service between client and the management system to allow pushing
messages to clients from server side.
The message service is implemented using a technique called long
polling~\cite{cite:push-pull} --- each message pull request waits on a
message queue which will block the pop request on empty until timeout
threshold exceeds.
This implementation gives the balance between the CPU cost of frequent
polling and the cost of maintaining long connections as notification
channel.

\subsection{Adaptive Adjustment}

As we have the status checker periodically collecting system information
and runtime information about tasks, we can use them to help to improve
scheduling accuracy or adapt to accidental events.

For example, some scheduling policies would require to have expected
runtime of a task, which is sometimes unavailable.
In that case, it can use the default value first, and after several
tasks are done, we can provide the logged statistics for scheduling.
Moreover, machine performance degrade or temporary network congestion
may lower the accuracy of expected runtime of jobs given by user.
Leveraging the runtime statistics can improve the quality of
scheduling.

Another case is about worker failure.
In data centers, workers may fail or recover any time.
Worker failure will cause execution progress delay and very possibly
will result in deadline miss.
In that case, if it is able to recover failed workers, the schedule plan
should change and give more resource to delayed jobs (if possible) so
that it may be able to meet the deadline.

To achieve this, while collecting informations, status checker also
asks decision maker to schedule with updated information so that the
system schedule plan can catch up with current conditions.
