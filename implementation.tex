\chapter{Implementation}\label{sec:impl}  % [lmr3796] added

\section{System Flow}	%%% [DS] added

Figure~\ref{fig:archi-overview} shows our system flow. Each arrow on the
figure indicates the communication between the components.
\begin{enumerate}
  \item The client sends a job request to the Dispatcher in the management 
    system.
  \item According to the pre-defined policy and current worker status,
    decision maker generates a resource allocation plan.
  \item Once the worker is ready, dispatcher responds to the client
    about which worker and corresponding job the client should execute
    next task on.
  \item The client transfer the required data to workers.
  \item The client sends tells the management system a task is sent
    ,maintaining remaining tasks of each job is critical to scheduling.
  \item After finishing the task, the worker sends ``job done'' signal
    to the management system.

  \item On receiving the ``job done'' signal, the management system
    informs the corresponding client.
  
  \item The client collects the job results from workers, and

  \item send an acknowledgement to workers after the transmission is
    completed.
  \item Last, the worker send a ``clear'' signal to management system.
\end{enumerate}
Aside from the normal job execution flow, status checker will
periodically collects the system information for scheduling, including
detecting worker healthiness.
The scheduling process only happens whenever there is 
\begin{enumerate}
  \item job change, including submission or completion, or
  \item worker change, including worker failure or rejoin.
\end{enumerate}

\section{RPC Server Component}

% RPC server design
We implemented the components in the management system and the worker as
separate RPC (remote procedural call)~\cite{cite:RPC} servers.
Separate RPC server implementation makes each component
\emph{pluggable}.
The pluggability gives the system administrator flexibility to choose
the most suitable component implementation to fit different needs.
Moreover, without shutting the whole system down, it is possible to
change system configurations --- or even upgrade the system --- by
substituting target components with feasible ones.
Besides, this design allows us to easily integrate the management system
with other cluster management frameworks like JPPF~\cite{cite:JPPF} or
cloud operating system like Roystonea~\cite{cite:roystonea}.
Roystonea also benefits from the RPC server implementation.

\section{Message Service}

Our implementation is a pure client-server model, which means the
management system and workers cannot actively contact the clients.
However, it is essential for workers and the management system to notify
clients to submit tasks or get back execution results as soon as a task
is done.

It is extremely inefficient for both side and server side to keep the
connection between the client and the management system along the
period.
The connection may last over hours if we keep it alive between task
submission to worker and the finish of task execution, depending on how
long a task is required to execute.
Moreover, as the number of long-last connections increases, the
connection number limit from the operating system will become the
bottleneck of the management system.

In order to overcome this, we implemented a underlying message push
service between client and the management system to allow pushing
messages to clients from server side.
The message service is implemented using a technique called long
polling~\cite{cite:push-pull} --- each message pull request waits on a
message queue which will block the pop request on empty until timeout
threshold exceeds.
This implementation gives the balance between the CPU cost of frequent
polling and the cost of maintaining long connections as notification
channel.

\section{Adaptive Adjustment}

As we have the status checker periodically collecting system information
and runtime information about tasks, we can use them to help to improve
scheduling accuracy or adapt to accidental events.

For example, some scheduling policies would require to have expected
runtime of a task, which is sometimes unavailable.
In that case, it can use the default value first, and after several
tasks are done, we can provide the logged statistics for scheduling.
Moreover, machine performance degrade or temporary network congestion
may lower the accuracy of expected runtime of jobs given by user.
Leveraging the runtime statistics can improve the quality of
scheduling.

Another case is about worker failure.
In data centers, workers may fail or recover any time.
Worker failure will cause execution progress delay and very possibly
will result in deadline miss.
In that case, if it is able to recover failed workers, the schedule plan
should change and give more resource to delayed jobs (if possible) so
that it may be able to meet the deadline.

To achieve this, while collecting informations, status checker also
asks decision maker to schedule with updated information so that the
system schedule plan can catch up with current conditions.

This feature not only improves fault tolerance, but also let us choose a
more aggressive scheduling policy.
Originally, the scheduling policy should in order to handle emergency
jobs.
This critically lowers the throughput of the system.
Applying adaptive adjustment, the scheduling policy can aggressively
allocate all the resources without preserving them.
If emergency job comes, all we need is kill some low priority running
tasks and reallocate them to the high priority emergency ones.
As for the killed ones, it is just like handling worker failure; they
will be redo when there are available workers allocated for them.

