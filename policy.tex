\chapter{Policy}

In this chapter, we introduce the four policies in our system ---
\emph{priority-based}, \emph{proportion-based}, \emph{workload-based}
and \emph{deadline-based}.
Each policy requires different parameters such as job priority,
execution efficiency per different server and execution deadline.
The decision maker makes dispatching plans to according to a specified
policy.

When designing the schedule policies, one should take the number of
tasks a job is split into consideration since we don't want to assign
workers more than tasks of a job to it.
Recall that it is the end users' responsibility to split a job into well
balanced tasks; the more balanced the tasks, the better the system
schedules.


\section{Priority-based Policy}

%%% Introduce Priority-based
\emph{Priority-based} distributes workloads according to job priority. 
The idea behind this policy is to make the job with highest priority runs as
fast as possible.
Intuitively, we can sort the jobs according to their priority then greedily
schedule as many workers as possible to each job in that order.
However, this might cause \emph{starvation} --- lower priority jobs
never get executed.

% TODO try to say more...

%%% How we avoid starvation from happening
To avoid \emph{starvation}, we preserve a portion for low priority jobs.
We set a reservation rate $r \in [0,1]$ that the portion $r$ of workers
will be reserved for low priority jobs.
The job with highest priorities can use at most the $1-r$ of all workers
and the remaining workers, including those are not reserved but still not
assigned to the highest priority job because of the task amount limit,
will be assigned to jobs with lower priority, in the manner that one job
receives one worker.
The complete algorithm is shown as algorithm~\ref{algo:priority-based}.

\begin{algorithm}[H]
  \DontPrintSemicolon % Some LaTeX compilers require you to use
  \input{snippets/policies/priority-based-policy}
  \caption{Priority-based policy}
  \label{algo:priority-based}
\end{algorithm}

\section{Proportion-based Policy}

In contrast to priority-based, this policy is takes job priorities into
consideration very little; instead, the main concern of this policy is
the workload proportion of a job to all the others.
This algorithm, as shown in algorithm~\ref{algo:proportion-based}, is
also known as \emph{fair share
scheduling}~\cite{cite:fair-share-scheduling}: workers a job should be
allocated is in proportion to its workload proportion to all jobs. 

% TODO For streaming jobs, workloads may varies: For streaming jobs
% dependent on others, if they don't have anything to process, its
% workload is low so no workers needed, but as results come out, we
% should give it servers.

\begin{algorithm}[H]
  \DontPrintSemicolon % Some LaTeX compilers require you to use
  \input{snippets/policies/proportion-based-policy}
  \caption{Proportion-based policy}
  \label{algo:proportion-based}
\end{algorithm}

\section{Workload-based Policy}

Similar to the proportion-based policy, the main concern of the
workload-based policy is the workload of the job.
The main difference is, rather than fair sharing, this policy tends to
meet the workload requirement of high priority jobs.

\subsection{Model Definition}

We represent each job $j_i$ submitted as $j_i = (w_i, p_i, n_i)$, where
$w_i, p_i, n_i$ represents the estimated workload, priority and the
number of task of $j_i$ respectively.
As for the workers, we model each worker $s_k$ as a vector of estimated
\emph{throughput} of each submitted job; we can write is as $s_k =
(th^k_1, th^k_2, \ldots)$.


\subsection{Algorithm}

The approach is a simple greedy method:
First, sort the jobs by priority.
For each job $J_m$, sort remaining workers according to its $th_m$,
assign top $k$ workers that just satisfy the workload requirement of
$J_m$ and remove assigned workers from the list.
If workers are used up, break the loop.
The complete algorithm is shown as algorithm ~\ref{algo:workload-based}.

\begin{algorithm}[H]
  \DontPrintSemicolon % Some LaTeX compilers require you to use
  \input{snippets/policies/workload-based-policy}
  \caption{Workload-based policy}
  \label{algo:workload-based}
\end{algorithm}

\section{Deadline-based Policy}

Plenty kinds of jobs must be finished before a given deadline.
For example, as a Internet service provider, settling monthly bills of
millions of users within few days after the monthly charge-off day is
very critical to their business.
It it obvious that computing resource allocated this kind of job should
increase as their deadline approaches --- the closer the deadline is, the
more worker a job should get.
Unfortunately, policies introduced in previous sections can't directly
adapt to this need; hence, we introduce another policy designed for
\emph{deadline-aware} scenarios.

\subsection{Model Definition}

For this policy, we assume that each job is provided with priority and
deadline and we have required execution time (which may be a estimated
one) of a job to run on each single server.
A job $j_i$ can thus be represented as $j_i = (d_i, p_i, n_i)$, where
$d_i, p_i, n_i$ refers to the deadline, priority and the number of tasks
of $j_i$ respectively, and the workers are modeled as a vector of
estimated execution time of each submitted job: $s_k = (T^k_1, T^k_2,
\ldots)$, similar to the previous policy.

\subsection{Algorithm}

Intuitively, for the same job, if the deadline is twice tighter, it
requires twice as many workers to meet that deadline.
More generally speaking, the deadline and the workload are in reciprocal
relationship.

This implies that an worker allocation $S$ to job $j_i$ meeting the
deadline is equivalent to
\[\displaystyle\sum_{s_k \in S}\frac{1}{T^k_{j_i}} \geq \frac{1}{d_i}\]
With this observation, only a little modification on the workload-based
policy is needed to apply to this model: simply use the inverse of
deadline as throughput.

\begin{algorithm}[H]
  \DontPrintSemicolon % Some LaTeX compilers require you to use
  \input{snippets/policies/deadline-based-policy}
  \caption{Deadline-based policy}
  \label{algo:deadline-based}
\end{algorithm}
